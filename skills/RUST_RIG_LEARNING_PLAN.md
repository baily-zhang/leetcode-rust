# Rust + Rig å­¦ä¹ è®¡åˆ’

> ç›®æ ‡ï¼š4-5 å‘¨å†…å®Œæˆå­¦ä¹ ï¼Œäº§å‡ºä¸€ä¸ªå¯æ”¾å…¥ç®€å†çš„ RAG é¡¹ç›®
>
> æ¯æ—¥æŠ•å…¥ï¼š3-4 å°æ—¶
>
> å‰ç½®æ¡ä»¶ï¼šå·²æŒæ¡ Rust åŸºç¡€è¯­æ³•ã€traitsã€æ³›å‹

---

## ç¬¬ä¸€å‘¨ï¼šå¼‚æ­¥ Rust åŸºç¡€

### Day 1: ç†è§£ async/await æ¦‚å¿µ

**å­¦ä¹ å†…å®¹ï¼š**
- [x] ä»€ä¹ˆæ˜¯ Future
- [x] async fn è¿”å›ä»€ä¹ˆ
- [x] .await åšäº†ä»€ä¹ˆ
- [x] ä¸ºä»€ä¹ˆéœ€è¦è¿è¡Œæ—¶ï¼ˆRuntimeï¼‰

**èµ„æºï¼š**
- é˜…è¯»ï¼šhttps://rust-lang.github.io/async-book/01_getting_started/01_chapter.html
- é˜…è¯»ï¼šhttps://rust-lang.github.io/async-book/01_getting_started/04_async_await_primer.html

**ç»ƒä¹ ï¼š**
```rust
// å†™ä¸€ä¸ª async å‡½æ•°ï¼Œç†è§£å®ƒè¿”å›çš„ç±»å‹
async fn hello() -> String {
    "Hello".to_string()
}

fn main() {
    let future = hello(); // è¿™æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿ
    // å°è¯•æ‰“å° future çš„ç±»å‹
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [x] èƒ½è§£é‡Š Future trait çš„åŸºæœ¬ç»“æ„
- [x] ç†è§£ lazy evaluationï¼ˆæƒ°æ€§æ±‚å€¼ï¼‰

---

### Day 2: Tokio å…¥é—¨

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] å®‰è£…å’Œé…ç½® Tokio
- [ ] `#[tokio::main]` å®çš„ä½œç”¨
- [ ] tokio::spawn åˆ›å»ºä»»åŠ¡
- [ ] tokio::time::sleep vs std::thread::sleep

**èµ„æºï¼š**
- å®˜æ–¹æ•™ç¨‹ï¼šhttps://tokio.rs/tokio/tutorial

**ç»ƒä¹ é¡¹ç›®ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„å¼‚æ­¥è®¡æ—¶å™¨**
```bash
cargo new async-timer
cd async-timer
```

```toml
# Cargo.toml
[dependencies]
tokio = { version = "1", features = ["full"] }
```

```rust
// src/main.rs
use tokio::time::{sleep, Duration};

#[tokio::main]
async fn main() {
    println!("å¼€å§‹è®¡æ—¶...");

    // ä»»åŠ¡1ï¼š3ç§’åæ‰“å°
    let task1 = tokio::spawn(async {
        sleep(Duration::from_secs(3)).await;
        println!("ä»»åŠ¡1å®Œæˆï¼ˆ3ç§’ï¼‰");
    });

    // ä»»åŠ¡2ï¼š1ç§’åæ‰“å°
    let task2 = tokio::spawn(async {
        sleep(Duration::from_secs(1)).await;
        println!("ä»»åŠ¡2å®Œæˆï¼ˆ1ç§’ï¼‰");
    });

    // ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡
    let _ = tokio::join!(task1, task2);
    println!("å…¨éƒ¨å®Œæˆ");
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ä¸ºä»€ä¹ˆä»»åŠ¡2å…ˆå®Œæˆï¼ˆå¹¶å‘ vs å¹¶è¡Œï¼‰
- [ ] èƒ½è§£é‡Š tokio::spawn çš„ä½œç”¨

---

### Day 3: å¼‚æ­¥ I/O

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] tokio::fs æ–‡ä»¶æ“ä½œ
- [ ] tokio::io è¯»å†™
- [ ] BufReader / BufWriter

**ç»ƒä¹ é¡¹ç›®ï¼šå¼‚æ­¥æ–‡ä»¶è¯»å–å™¨**
```rust
use tokio::fs::File;
use tokio::io::{AsyncBufReadExt, BufReader};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let file = File::open("test.txt").await?;
    let reader = BufReader::new(file);
    let mut lines = reader.lines();

    while let Some(line) = lines.next_line().await? {
        println!("{}", line);
    }

    Ok(())
}
```

**æ‰©å±•ç»ƒä¹ ï¼š**
- [ ] åŒæ—¶è¯»å–å¤šä¸ªæ–‡ä»¶ï¼Œç»Ÿè®¡æ€»è¡Œæ•°
- [ ] å†™ä¸€ä¸ªå¼‚æ­¥çš„æ–‡ä»¶å¤åˆ¶å‡½æ•°

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ `?` åœ¨ async å‡½æ•°ä¸­çš„å·¥ä½œæ–¹å¼
- [ ] èƒ½å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨çš„é”™è¯¯

---

### Day 4: HTTP å®¢æˆ·ç«¯ (reqwest)

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] reqwest åº“çš„ä½¿ç”¨
- [ ] GET/POST è¯·æ±‚
- [ ] JSON åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼ˆserdeï¼‰

**ç»ƒä¹ é¡¹ç›®ï¼šGitHub API å®¢æˆ·ç«¯**
```bash
cargo new github-client
```

```toml
# Cargo.toml
[dependencies]
tokio = { version = "1", features = ["full"] }
reqwest = { version = "0.12", features = ["json"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
```

```rust
use serde::Deserialize;

#[derive(Debug, Deserialize)]
struct GitHubUser {
    login: String,
    id: u64,
    public_repos: u32,
    followers: u32,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = reqwest::Client::new();

    let user: GitHubUser = client
        .get("https://api.github.com/users/rust-lang")
        .header("User-Agent", "rust-learning")
        .send()
        .await?
        .json()
        .await?;

    println!("ç”¨æˆ·: {}", user.login);
    println!("å…¬å¼€ä»“åº“: {}", user.public_repos);
    println!("ç²‰ä¸: {}", user.followers);

    Ok(())
}
```

**æ‰©å±•ç»ƒä¹ ï¼š**
- [ ] æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŸ¥è¯¢ä»»æ„ç”¨æˆ·
- [ ] å¹¶å‘æŸ¥è¯¢å¤šä¸ªç”¨æˆ·ï¼Œæ¯”è¾ƒå“åº”æ—¶é—´

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ serde çš„ Deserialize æ´¾ç”Ÿå®
- [ ] èƒ½å¤„ç† API è¿”å›çš„é”™è¯¯ï¼ˆ404 ç­‰ï¼‰

---

### Day 5: é”™è¯¯å¤„ç†æ·±å…¥

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] è‡ªå®šä¹‰é”™è¯¯ç±»å‹
- [ ] thiserror åº“
- [ ] anyhow åº“
- [ ] ä½•æ—¶ç”¨ thiserror vs anyhow

**èµ„æºï¼š**
- thiserror: https://docs.rs/thiserror/latest/thiserror/
- anyhow: https://docs.rs/anyhow/latest/anyhow/

**ç»ƒä¹ ï¼šé‡æ„ Day 4 çš„é¡¹ç›®**
```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum AppError {
    #[error("HTTP è¯·æ±‚å¤±è´¥: {0}")]
    HttpError(#[from] reqwest::Error),

    #[error("ç”¨æˆ· '{0}' ä¸å­˜åœ¨")]
    UserNotFound(String),

    #[error("API é™æµï¼Œè¯·ç¨åé‡è¯•")]
    RateLimited,
}

async fn get_user(username: &str) -> Result<GitHubUser, AppError> {
    let response = reqwest::get(format!(
        "https://api.github.com/users/{}",
        username
    )).await?;

    match response.status().as_u16() {
        200 => Ok(response.json().await?),
        404 => Err(AppError::UserNotFound(username.to_string())),
        403 => Err(AppError::RateLimited),
        _ => Err(AppError::HttpError(response.error_for_status().unwrap_err())),
    }
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ #[from] å±æ€§çš„ä½œç”¨
- [ ] èƒ½è§£é‡Š thiserror vs anyhow çš„ä½¿ç”¨åœºæ™¯

---

### Day 6-7: ç¬¬ä¸€å‘¨é¡¹ç›® - å¤©æ°” CLI

**ç›®æ ‡ï¼š** æ•´åˆæœ¬å‘¨æ‰€å­¦ï¼Œåšä¸€ä¸ªå‘½ä»¤è¡Œå¤©æ°”æŸ¥è¯¢å·¥å…·

**åŠŸèƒ½è¦æ±‚ï¼š**
- [ ] æ¥æ”¶åŸå¸‚åä½œä¸ºå‚æ•°
- [ ] è°ƒç”¨å¤©æ°” APIï¼ˆæ¨è wttr.in æˆ– OpenWeatherMapï¼‰
- [ ] æ˜¾ç¤ºæ¸©åº¦ã€æ¹¿åº¦ã€å¤©æ°”æè¿°
- [ ] ä¼˜é›…çš„é”™è¯¯å¤„ç†
- [ ] æ”¯æŒæŸ¥è¯¢å¤šä¸ªåŸå¸‚ï¼ˆå¹¶å‘ï¼‰

**é¡¹ç›®ç»“æ„ï¼š**
```
weather-cli/
â”œâ”€â”€ Cargo.toml
â””â”€â”€ src/
    â”œâ”€â”€ main.rs      # å…¥å£ï¼Œå‚æ•°è§£æ
    â”œâ”€â”€ api.rs       # API è°ƒç”¨
    â”œâ”€â”€ error.rs     # é”™è¯¯ç±»å‹
    â””â”€â”€ models.rs    # æ•°æ®ç»“æ„
```

**ä¾èµ–ï¼š**
```toml
[dependencies]
tokio = { version = "1", features = ["full"] }
reqwest = { version = "0.12", features = ["json"] }
serde = { version = "1", features = ["derive"] }
clap = { version = "4", features = ["derive"] }
thiserror = "2"
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç¨‹åºèƒ½æ­£ç¡®è¿è¡Œ
- [ ] é”™è¯¯ä¿¡æ¯å‹å¥½
- [ ] ä»£ç ç»“æ„æ¸…æ™°

---

## ç¬¬äºŒå‘¨ï¼šRig åŸºç¡€

### Day 8: Rig å®‰è£…å’Œç¬¬ä¸€ä¸ªç¨‹åº

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] Rig æ¶æ„æ¦‚è§ˆ
- [ ] è®¾ç½® OpenAI API Key
- [ ] ç¬¬ä¸€ä¸ª Rig ç¨‹åº

**å‡†å¤‡å·¥ä½œï¼š**
1. è·å– OpenAI API Key: https://platform.openai.com/api-keys
2. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   ```bash
   export OPENAI_API_KEY="sk-..."
   ```

**é¡¹ç›®è®¾ç½®ï¼š**
```bash
cargo new rig-hello
cd rig-hello
```

```toml
# Cargo.toml
[dependencies]
rig-core = "0.9"
tokio = { version = "1", features = ["full"] }
```

```rust
// src/main.rs
use rig::providers::openai;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // ä»ç¯å¢ƒå˜é‡è¯»å– API Key
    let client = openai::Client::from_env();

    // åˆ›å»ºä¸€ä¸ª agent
    let agent = client
        .agent(openai::GPT_4O)
        .preamble("ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚")
        .build();

    // å‘é€è¯·æ±‚
    let response = agent.prompt("ä»€ä¹ˆæ˜¯ Rust è¯­è¨€ï¼Ÿ").await?;

    println!("{}", response);

    Ok(())
}
```

**ç»ƒä¹ ï¼š**
- [ ] ä¿®æ”¹ preambleï¼Œè®©å®ƒæ‰®æ¼”ä¸åŒè§’è‰²
- [ ] å°è¯•ä¸åŒçš„æ¨¡å‹ï¼ˆGPT_4O_MINI ç­‰ï¼‰

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç¨‹åºæˆåŠŸè¿è¡Œå¹¶è¿”å›å“åº”
- [ ] ç†è§£ Client -> Agent -> Prompt çš„æµç¨‹

---

### Day 9: ç†è§£ Rig çš„ Agent ç³»ç»Ÿ

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] Agent vs Completion
- [ ] Agent Builder æ¨¡å¼
- [ ] Temperatureã€Max Tokens ç­‰å‚æ•°
- [ ] å¤šè½®å¯¹è¯

**ç»ƒä¹ ï¼šå¸¦å†å²è®°å½•çš„å¯¹è¯**
```rust
use rig::providers::openai;
use rig::agent::Agent;
use std::io::{self, Write};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = openai::Client::from_env();
    let agent = client
        .agent(openai::GPT_4O_MINI)
        .preamble("ä½ æ˜¯ä¸€ä¸ª Rust ç¼–ç¨‹åŠ©æ‰‹ã€‚")
        .temperature(0.7)
        .build();

    let mut history = Vec::new();

    loop {
        print!("ä½ : ");
        io::stdout().flush()?;

        let mut input = String::new();
        io::stdin().read_line(&mut input)?;
        let input = input.trim();

        if input == "quit" || input == "exit" {
            break;
        }

        // æ„å»ºå¸¦å†å²çš„ prompt
        let full_prompt = if history.is_empty() {
            input.to_string()
        } else {
            format!("{}\n\nç”¨æˆ·: {}", history.join("\n"), input)
        };

        let response = agent.prompt(&full_prompt).await?;
        println!("åŠ©æ‰‹: {}\n", response);

        history.push(format!("ç”¨æˆ·: {}\nåŠ©æ‰‹: {}", input, response));
    }

    Ok(())
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ temperature å‚æ•°çš„å½±å“
- [ ] èƒ½å®ç°åŸºæœ¬çš„å¤šè½®å¯¹è¯

---

### Day 10: Tool Useï¼ˆå·¥å…·è°ƒç”¨ï¼‰

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] ä»€ä¹ˆæ˜¯ Tool Use / Function Calling
- [ ] åœ¨ Rig ä¸­å®šä¹‰å·¥å…·
- [ ] Agent å¦‚ä½•é€‰æ‹©å’Œè°ƒç”¨å·¥å…·

**ç»ƒä¹ ï¼šè®¡ç®—å™¨å·¥å…·**
```rust
use rig::providers::openai;
use rig::tool::Tool;
use serde::{Deserialize, Serialize};

#[derive(Deserialize)]
struct CalculatorInput {
    operation: String,
    a: f64,
    b: f64,
}

#[derive(Serialize)]
struct CalculatorOutput {
    result: f64,
}

#[derive(Debug, thiserror::Error)]
#[error("è®¡ç®—é”™è¯¯: {0}")]
struct CalculatorError(String);

struct Calculator;

impl Tool for Calculator {
    const NAME: &'static str = "calculator";

    type Error = CalculatorError;
    type Args = CalculatorInput;
    type Output = CalculatorOutput;

    async fn definition(&self, _prompt: String) -> rig::tool::ToolDefinition {
        rig::tool::ToolDefinition {
            name: "calculator".to_string(),
            description: "æ‰§è¡ŒåŸºæœ¬æ•°å­¦è¿ç®—ï¼ˆadd, subtract, multiply, divideï¼‰".to_string(),
            parameters: serde_json::json!({
                "type": "object",
                "properties": {
                    "operation": {
                        "type": "string",
                        "enum": ["add", "subtract", "multiply", "divide"]
                    },
                    "a": { "type": "number" },
                    "b": { "type": "number" }
                },
                "required": ["operation", "a", "b"]
            }),
        }
    }

    async fn call(&self, args: Self::Args) -> Result<Self::Output, Self::Error> {
        let result = match args.operation.as_str() {
            "add" => args.a + args.b,
            "subtract" => args.a - args.b,
            "multiply" => args.a * args.b,
            "divide" => {
                if args.b == 0.0 {
                    return Err(CalculatorError("é™¤æ•°ä¸èƒ½ä¸ºé›¶".to_string()));
                }
                args.a / args.b
            }
            _ => return Err(CalculatorError("æœªçŸ¥æ“ä½œ".to_string())),
        };

        Ok(CalculatorOutput { result })
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = openai::Client::from_env();

    let agent = client
        .agent(openai::GPT_4O)
        .preamble("ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨è®¡ç®—å™¨å·¥å…·è¿›è¡Œè®¡ç®—ã€‚")
        .tool(Calculator)
        .build();

    let response = agent.prompt("è®¡ç®— 123 ä¹˜ä»¥ 456 æ˜¯å¤šå°‘ï¼Ÿ").await?;
    println!("{}", response);

    Ok(())
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ Tool trait çš„ç»“æ„
- [ ] èƒ½æ·»åŠ æ–°çš„å·¥å…·å‡½æ•°

---

### Day 11: å‘é‡åµŒå…¥ï¼ˆEmbeddingsï¼‰

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] ä»€ä¹ˆæ˜¯ Embedding
- [ ] ä¸ºä»€ä¹ˆéœ€è¦ Embeddingï¼ˆè¯­ä¹‰æœç´¢ï¼‰
- [ ] Rig ä¸­çš„ Embedding API

**ç»ƒä¹ ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—**
```rust
use rig::providers::openai;
use rig::embeddings::EmbeddingsBuilder;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = openai::Client::from_env();

    let model = client.embedding_model(openai::TEXT_EMBEDDING_3_SMALL);

    let texts = vec![
        "Rust æ˜¯ä¸€é—¨ç³»ç»Ÿç¼–ç¨‹è¯­è¨€",
        "Python æ˜¯ä¸€é—¨è§£é‡Šå‹è¯­è¨€",
        "Rust æ³¨é‡å†…å­˜å®‰å…¨å’Œæ€§èƒ½",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
    ];

    let embeddings = EmbeddingsBuilder::new(model.clone())
        .documents(texts.clone())?
        .build()
        .await?;

    // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    fn cosine_similarity(a: &[f64], b: &[f64]) -> f64 {
        let dot: f64 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
        let norm_a: f64 = a.iter().map(|x| x * x).sum::<f64>().sqrt();
        let norm_b: f64 = b.iter().map(|x| x * x).sum::<f64>().sqrt();
        dot / (norm_a * norm_b)
    }

    let query = "Rust çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆ";
    let query_embedding = model.embed_text(query).await?;

    println!("æŸ¥è¯¢: {}\n", query);
    for (i, embedding) in embeddings.iter().enumerate() {
        let similarity = cosine_similarity(&query_embedding.vec, &embedding.vec);
        println!("ç›¸ä¼¼åº¦ {:.4}: {}", similarity, texts[i]);
    }

    Ok(())
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ Embedding çš„æ¦‚å¿µ
- [ ] è§‚å¯Ÿè¯­ä¹‰ç›¸ä¼¼çš„å¥å­å¾—åˆ†æ›´é«˜

---

### Day 12-13: RAG åŸºç¡€

**å­¦ä¹ å†…å®¹ï¼š**
- [ ] RAG æ˜¯ä»€ä¹ˆï¼ˆRetrieval Augmented Generationï¼‰
- [ ] RAG çš„æµç¨‹ï¼šç´¢å¼• -> æ£€ç´¢ -> ç”Ÿæˆ
- [ ] Rig çš„å‘é‡å­˜å‚¨

**ç»ƒä¹ ï¼šç®€å•çš„å†…å­˜ RAG**
```rust
use rig::providers::openai;
use rig::vector_store::in_memory_store::InMemoryVectorStore;
use rig::embeddings::EmbeddingsBuilder;
use rig::vector_store::VectorStoreIndex;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = openai::Client::from_env();
    let embedding_model = client.embedding_model(openai::TEXT_EMBEDDING_3_SMALL);

    // çŸ¥è¯†åº“æ–‡æ¡£
    let documents = vec![
        "Rust çš„æ‰€æœ‰æƒç³»ç»Ÿç¡®ä¿å†…å­˜å®‰å…¨ï¼Œæ— éœ€åƒåœ¾å›æ”¶å™¨ã€‚",
        "Rust çš„å€Ÿç”¨æ£€æŸ¥å™¨åœ¨ç¼–è¯‘æ—¶é˜²æ­¢æ•°æ®ç«äº‰ã€‚",
        "Cargo æ˜¯ Rust çš„åŒ…ç®¡ç†å™¨å’Œæ„å»ºå·¥å…·ã€‚",
        "Rust çš„ trait ç±»ä¼¼äºå…¶ä»–è¯­è¨€çš„æ¥å£ã€‚",
        "Rust å¯ä»¥ç¼–è¯‘ä¸º WebAssemblyï¼Œåœ¨æµè§ˆå™¨ä¸­è¿è¡Œã€‚",
    ];

    // åˆ›å»ºåµŒå…¥
    let embeddings = EmbeddingsBuilder::new(embedding_model.clone())
        .documents(documents.clone())?
        .build()
        .await?;

    // åˆ›å»ºå‘é‡å­˜å‚¨
    let vector_store = InMemoryVectorStore::from_documents(embeddings);
    let index = vector_store.index(embedding_model);

    // æ£€ç´¢ç›¸å…³æ–‡æ¡£
    let query = "Rust å¦‚ä½•ä¿è¯å†…å­˜å®‰å…¨ï¼Ÿ";
    let results = index.top_n::<String>(query, 2).await?;

    println!("æŸ¥è¯¢: {}\n", query);
    println!("ç›¸å…³æ–‡æ¡£:");
    for (score, _, doc) in &results {
        println!("  [{:.4}] {}", score, doc);
    }

    // æ„å»º RAG prompt
    let context: Vec<_> = results.iter().map(|(_, _, doc)| doc.as_str()).collect();
    let rag_prompt = format!(
        "æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ã€‚\n\nä¿¡æ¯ï¼š\n{}\n\né—®é¢˜ï¼š{}",
        context.join("\n"),
        query
    );

    let agent = client
        .agent(openai::GPT_4O_MINI)
        .build();

    let response = agent.prompt(&rag_prompt).await?;
    println!("\nå›ç­”: {}", response);

    Ok(())
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç†è§£ RAG çš„å®Œæ•´æµç¨‹
- [ ] èƒ½è§£é‡Šä¸ºä»€ä¹ˆ RAG æ¯”ç›´æ¥é—® LLM æ•ˆæœæ›´å¥½

---

### Day 14: ç¬¬äºŒå‘¨å›é¡¾å’Œå·©å›º

**ä»»åŠ¡ï¼š**
- [ ] å›é¡¾æœ¬å‘¨ä»£ç ï¼Œç¡®ä¿æ¯ä¸ªæ¦‚å¿µéƒ½ç†è§£
- [ ] æ•´ç†ç¬”è®°
- [ ] è§£å†³é—ç•™é—®é¢˜

**è‡ªæµ‹é—®é¢˜ï¼š**
1. Agent å’Œ Completion çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
2. Tool trait éœ€è¦å®ç°å“ªäº›å…³è”ç±»å‹ï¼Ÿ
3. Embedding å‘é‡çš„ç»´åº¦ä»£è¡¨ä»€ä¹ˆï¼Ÿ
4. RAG ä¸­çš„ "R"ã€"A"ã€"G" åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ

---

## ç¬¬ä¸‰å‘¨ï¼šé¡¹ç›®å¼€å‘ - PDF é—®ç­”åŠ©æ‰‹

### Day 15: é¡¹ç›®æ¶æ„è®¾è®¡

**é¡¹ç›®ç›®æ ‡ï¼š**
æ„å»ºä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œå¯ä»¥ï¼š
1. åŠ è½½ PDF æ–‡ä»¶
2. å°†å†…å®¹åˆ‡åˆ†å¹¶å»ºç«‹ç´¢å¼•
3. å›ç­”å…³äº PDF å†…å®¹çš„é—®é¢˜

**æŠ€æœ¯æ ˆï¼š**
- Rigï¼ˆLLM å’Œ Embeddingï¼‰
- pdf-extractï¼ˆPDF è§£æï¼‰
- å†…å­˜å‘é‡å­˜å‚¨

**é¡¹ç›®ç»“æ„ï¼š**
```
pdf-qa/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs           # CLI å…¥å£
â”‚   â”œâ”€â”€ lib.rs            # åº“å…¥å£
â”‚   â”œâ”€â”€ pdf/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ parser.rs     # PDF è§£æ
â”‚   â”œâ”€â”€ index/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ chunker.rs    # æ–‡æœ¬åˆ‡åˆ†
â”‚   â”‚   â””â”€â”€ store.rs      # å‘é‡å­˜å‚¨
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ qa.rs         # é—®ç­” Agent
â”‚   â””â”€â”€ error.rs          # é”™è¯¯ç±»å‹
â””â”€â”€ tests/
    â””â”€â”€ integration.rs
```

**ä¾èµ–ï¼š**
```toml
[dependencies]
rig-core = "0.9"
tokio = { version = "1", features = ["full"] }
pdf-extract = "0.7"
clap = { version = "4", features = ["derive"] }
thiserror = "2"
anyhow = "1"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] é¡¹ç›®ç»“æ„åˆ›å»ºå®Œæˆ
- [ ] æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ

---

### Day 16: PDF è§£ææ¨¡å—

**ä»»åŠ¡ï¼š** å®ç° PDF æ–‡æœ¬æå–

```rust
// src/pdf/parser.rs
use std::path::Path;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum PdfError {
    #[error("æ— æ³•è¯»å–æ–‡ä»¶: {0}")]
    IoError(#[from] std::io::Error),

    #[error("PDF è§£æå¤±è´¥: {0}")]
    ParseError(String),
}

pub struct PdfDocument {
    pub path: String,
    pub content: String,
    pub page_count: usize,
}

impl PdfDocument {
    pub fn load<P: AsRef<Path>>(path: P) -> Result<Self, PdfError> {
        let path_str = path.as_ref().display().to_string();
        let bytes = std::fs::read(&path)?;

        let content = pdf_extract::extract_text_from_mem(&bytes)
            .map_err(|e| PdfError::ParseError(e.to_string()))?;

        // ä¼°ç®—é¡µæ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
        let page_count = content.matches("\x0c").count().max(1);

        Ok(Self {
            path: path_str,
            content,
            page_count,
        })
    }

    pub fn preview(&self, chars: usize) -> &str {
        if self.content.len() <= chars {
            &self.content
        } else {
            &self.content[..chars]
        }
    }
}
```

**æµ‹è¯•ï¼š**
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_load_pdf() {
        // ä¸‹è½½ä¸€ä¸ªæµ‹è¯• PDF æˆ–ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
        let doc = PdfDocument::load("test.pdf").unwrap();
        assert!(!doc.content.is_empty());
    }
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] èƒ½æˆåŠŸæå– PDF æ–‡æœ¬
- [ ] é”™è¯¯å¤„ç†å®Œå–„

---

### Day 17: æ–‡æœ¬åˆ‡åˆ†æ¨¡å—

**ä»»åŠ¡ï¼š** å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºé€‚åˆ Embedding çš„å°å—

```rust
// src/index/chunker.rs

#[derive(Debug, Clone)]
pub struct Chunk {
    pub id: usize,
    pub content: String,
    pub start_char: usize,
    pub end_char: usize,
}

pub struct ChunkerConfig {
    pub chunk_size: usize,      // æ¯å—çš„ç›®æ ‡å­—ç¬¦æ•°
    pub chunk_overlap: usize,   // å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
}

impl Default for ChunkerConfig {
    fn default() -> Self {
        Self {
            chunk_size: 500,
            chunk_overlap: 50,
        }
    }
}

pub struct Chunker {
    config: ChunkerConfig,
}

impl Chunker {
    pub fn new(config: ChunkerConfig) -> Self {
        Self { config }
    }

    pub fn chunk(&self, text: &str) -> Vec<Chunk> {
        let mut chunks = Vec::new();
        let mut start = 0;
        let mut id = 0;

        while start < text.len() {
            let end = (start + self.config.chunk_size).min(text.len());

            // å°è¯•åœ¨å¥å·æˆ–æ¢è¡Œå¤„æ–­å¼€
            let actual_end = self.find_break_point(text, start, end);

            let content = text[start..actual_end].trim().to_string();

            if !content.is_empty() {
                chunks.push(Chunk {
                    id,
                    content,
                    start_char: start,
                    end_char: actual_end,
                });
                id += 1;
            }

            // ä¸‹ä¸€å—çš„èµ·å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
            start = if actual_end >= text.len() {
                actual_end
            } else {
                actual_end.saturating_sub(self.config.chunk_overlap)
            };
        }

        chunks
    }

    fn find_break_point(&self, text: &str, start: usize, end: usize) -> usize {
        if end >= text.len() {
            return text.len();
        }

        // ä» end å¾€å‰æ‰¾å¥å·æˆ–æ¢è¡Œ
        let search_region = &text[start..end];

        for (i, c) in search_region.char_indices().rev() {
            if c == 'ã€‚' || c == '.' || c == '\n' {
                return start + i + c.len_utf8();
            }
        }

        // æ²¡æ‰¾åˆ°å¥½çš„æ–­ç‚¹ï¼Œå°±åœ¨ç©ºæ ¼å¤„æ–­å¼€
        for (i, c) in search_region.char_indices().rev() {
            if c.is_whitespace() {
                return start + i;
            }
        }

        end
    }
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] èƒ½æ­£ç¡®åˆ‡åˆ†ä¸­è‹±æ–‡æ–‡æœ¬
- [ ] é‡å æœºåˆ¶å·¥ä½œæ­£å¸¸

---

### Day 18: å‘é‡ç´¢å¼•æ¨¡å—

**ä»»åŠ¡ï¼š** é›†æˆ Rig å‘é‡å­˜å‚¨

```rust
// src/index/store.rs
use rig::providers::openai;
use rig::vector_store::in_memory_store::InMemoryVectorStore;
use rig::embeddings::EmbeddingsBuilder;
use rig::vector_store::VectorStoreIndex;
use crate::index::chunker::Chunk;

pub struct DocumentIndex {
    chunks: Vec<Chunk>,
    index: InMemoryVectorStore<openai::EmbeddingModel>,
}

impl DocumentIndex {
    pub async fn build(
        client: &openai::Client,
        chunks: Vec<Chunk>,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let embedding_model = client.embedding_model(openai::TEXT_EMBEDDING_3_SMALL);

        let contents: Vec<String> = chunks.iter()
            .map(|c| c.content.clone())
            .collect();

        let embeddings = EmbeddingsBuilder::new(embedding_model)
            .documents(contents)?
            .build()
            .await?;

        let store = InMemoryVectorStore::from_documents(embeddings);

        Ok(Self {
            chunks,
            index: store,
        })
    }

    pub async fn search(
        &self,
        query: &str,
        top_k: usize,
    ) -> Result<Vec<&Chunk>, Box<dyn std::error::Error>> {
        let embedding_model = /* ... */;
        let results = self.index
            .index(embedding_model)
            .top_n::<String>(query, top_k)
            .await?;

        // æ ¹æ®è¿”å›çš„å†…å®¹åŒ¹é…åŸå§‹ Chunk
        let matched_chunks: Vec<_> = results
            .iter()
            .filter_map(|(_, _, content)| {
                self.chunks.iter().find(|c| &c.content == content)
            })
            .collect();

        Ok(matched_chunks)
    }
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] ç´¢å¼•æ„å»ºæˆåŠŸ
- [ ] æœç´¢è¿”å›ç›¸å…³ç»“æœ

---

### Day 19: é—®ç­” Agent

**ä»»åŠ¡ï¼š** å®ç° RAG é—®ç­”é€»è¾‘

```rust
// src/agent/qa.rs
use rig::providers::openai;

pub struct QAAgent {
    client: openai::Client,
}

impl QAAgent {
    pub fn new(client: openai::Client) -> Self {
        Self { client }
    }

    pub async fn answer(
        &self,
        question: &str,
        context_chunks: &[&str],
    ) -> Result<String, Box<dyn std::error::Error>> {
        let context = context_chunks.join("\n\n---\n\n");

        let system_prompt = r#"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£é—®ç­”åŠ©æ‰‹ã€‚
æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è§„åˆ™ï¼š
1. åªæ ¹æ®æä¾›çš„å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœå†…å®¹ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
3. å¼•ç”¨å…·ä½“å†…å®¹æ—¶ï¼Œä¿æŒå‡†ç¡®
4. å›ç­”è¦ç®€æ´æ˜äº†"#;

        let user_prompt = format!(
            "æ–‡æ¡£å†…å®¹ï¼š\n{}\n\né—®é¢˜ï¼š{}",
            context, question
        );

        let agent = self.client
            .agent(openai::GPT_4O_MINI)
            .preamble(system_prompt)
            .build();

        let response = agent.prompt(&user_prompt).await?;

        Ok(response)
    }
}
```

**å®Œæˆæ ‡å‡†ï¼š**
- [ ] èƒ½æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”
- [ ] å½“ä¿¡æ¯ä¸è¶³æ—¶èƒ½æ­£ç¡®æç¤º

---

### Day 20-21: CLI æ•´åˆå’Œæµ‹è¯•

**ä»»åŠ¡ï¼š** å®Œæˆå‘½ä»¤è¡Œç•Œé¢

```rust
// src/main.rs
use clap::{Parser, Subcommand};
use pdf_qa::{PdfDocument, Chunker, ChunkerConfig, DocumentIndex, QAAgent};
use rig::providers::openai;
use std::io::{self, Write};

#[derive(Parser)]
#[command(name = "pdf-qa")]
#[command(about = "PDF æ–‡æ¡£é—®ç­”åŠ©æ‰‹")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// åŠ è½½ PDF å¹¶è¿›å…¥é—®ç­”æ¨¡å¼
    Chat {
        /// PDF æ–‡ä»¶è·¯å¾„
        #[arg(short, long)]
        file: String,
    },
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Chat { file } => {
            println!("æ­£åœ¨åŠ è½½ PDF: {}", file);
            let doc = PdfDocument::load(&file)?;
            println!("å·²åŠ è½½ {} é¡µï¼Œå…± {} å­—ç¬¦\n", doc.page_count, doc.content.len());

            println!("æ­£åœ¨å»ºç«‹ç´¢å¼•...");
            let chunker = Chunker::new(ChunkerConfig::default());
            let chunks = chunker.chunk(&doc.content);
            println!("å·²åˆ‡åˆ†ä¸º {} ä¸ªæ–‡æœ¬å—\n", chunks.len());

            let client = openai::Client::from_env();
            let index = DocumentIndex::build(&client, chunks).await?;
            let agent = QAAgent::new(client);

            println!("ç´¢å¼•å»ºç«‹å®Œæˆï¼å¼€å§‹é—®ç­”ï¼ˆè¾“å…¥ quit é€€å‡ºï¼‰\n");

            loop {
                print!("é—®é¢˜: ");
                io::stdout().flush()?;

                let mut input = String::new();
                io::stdin().read_line(&mut input)?;
                let input = input.trim();

                if input == "quit" || input == "exit" {
                    break;
                }

                if input.is_empty() {
                    continue;
                }

                // æ£€ç´¢ç›¸å…³å†…å®¹
                let relevant_chunks = index.search(input, 3).await?;
                let context: Vec<_> = relevant_chunks.iter()
                    .map(|c| c.content.as_str())
                    .collect();

                // ç”Ÿæˆå›ç­”
                let answer = agent.answer(input, &context).await?;
                println!("\nå›ç­”: {}\n", answer);
            }
        }
    }

    Ok(())
}
```

**æµ‹è¯•æ¸…å•ï¼š**
- [ ] åŠ è½½å°å‹ PDFï¼ˆ< 10 é¡µï¼‰
- [ ] åŠ è½½ä¸­å‹ PDFï¼ˆ10-50 é¡µï¼‰
- [ ] æµ‹è¯•ä¸­æ–‡ PDF
- [ ] æµ‹è¯•è‹±æ–‡ PDF
- [ ] æµ‹è¯•é”™è¯¯æƒ…å†µï¼ˆæ–‡ä»¶ä¸å­˜åœ¨ã€æ ¼å¼é”™è¯¯ï¼‰

---

## ç¬¬å››å‘¨ï¼šå®Œå–„å’Œéƒ¨ç½²

### Day 22-23: åŠŸèƒ½å¢å¼º

**å¯é€‰åŠŸèƒ½ï¼ˆé€‰æ‹© 2-3 ä¸ªå®ç°ï¼‰ï¼š**

1. **æŒä¹…åŒ–ç´¢å¼•**
   - å°†å‘é‡ç´¢å¼•ä¿å­˜åˆ°æ–‡ä»¶
   - ä¸‹æ¬¡åŠ è½½ç›¸åŒ PDF æ—¶è·³è¿‡ç´¢å¼•æ­¥éª¤

2. **æµå¼è¾“å‡º**
   - ä½¿ç”¨ Rig çš„ streaming API
   - å®æ—¶æ˜¾ç¤º AI å›ç­”

3. **å¤šæ–‡ä»¶æ”¯æŒ**
   - åŒæ—¶åŠ è½½å¤šä¸ª PDF
   - è·¨æ–‡ä»¶æœç´¢å’Œé—®ç­”

4. **å¼•ç”¨æ¥æº**
   - åœ¨å›ç­”ä¸­æ ‡æ³¨ä¿¡æ¯æ¥æºçš„é¡µç 
   - æ˜¾ç¤ºç›¸å…³åº¦åˆ†æ•°

5. **Web ç•Œé¢**
   - ä½¿ç”¨ Axum æˆ– Actix-web
   - ç®€å•çš„ä¸Šä¼ å’Œé—®ç­” UI

---

### Day 24-25: ä»£ç è´¨é‡

**ä»»åŠ¡ï¼š**

1. **æ·»åŠ æ–‡æ¡£æ³¨é‡Š**
```rust
/// PDF æ–‡æ¡£é—®ç­”åŠ©æ‰‹çš„æ ¸å¿ƒç´¢å¼•ç»“æ„
///
/// # Example
/// ```
/// let index = DocumentIndex::build(&client, chunks).await?;
/// let results = index.search("ä»€ä¹ˆæ˜¯æ‰€æœ‰æƒï¼Ÿ", 3).await?;
/// ```
pub struct DocumentIndex { ... }
```

2. **æ·»åŠ å•å…ƒæµ‹è¯•**
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chunker_basic() {
        let text = "è¿™æ˜¯ç¬¬ä¸€å¥ã€‚è¿™æ˜¯ç¬¬äºŒå¥ã€‚è¿™æ˜¯ç¬¬ä¸‰å¥ã€‚";
        let chunker = Chunker::new(ChunkerConfig {
            chunk_size: 10,
            chunk_overlap: 2,
        });
        let chunks = chunker.chunk(text);
        assert!(chunks.len() > 1);
    }
}
```

3. **è¿è¡Œ Clippy**
```bash
cargo clippy -- -D warnings
```

4. **æ ¼å¼åŒ–ä»£ç **
```bash
cargo fmt
```

---

### Day 26-27: README å’Œæ¼”ç¤º

**README.md æ¨¡æ¿ï¼š**
```markdown
# PDF-QA: æ™ºèƒ½æ–‡æ¡£é—®ç­”åŠ©æ‰‹

åŸºäº Rust å’Œ Rig æ¡†æ¶æ„å»ºçš„ RAG åº”ç”¨ï¼Œå¯ä»¥å¯¹ PDF æ–‡æ¡£è¿›è¡Œæ™ºèƒ½é—®ç­”ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸ” è¯­ä¹‰æœç´¢ï¼šä½¿ç”¨å‘é‡åµŒå…¥è¿›è¡Œæ™ºèƒ½æ£€ç´¢
- ğŸ’¬ è‡ªç„¶è¯­è¨€é—®ç­”ï¼šåŸºäºæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜
- âš¡ é«˜æ€§èƒ½ï¼šRust å®ç°ï¼Œå†…å­˜å®‰å…¨ä¸”é«˜æ•ˆ
- ğŸ“„ PDF æ”¯æŒï¼šè‡ªåŠ¨è§£æå’Œåˆ‡åˆ† PDF æ–‡æ¡£

## æŠ€æœ¯æ ˆ

- **è¯­è¨€**: Rust
- **LLM æ¡†æ¶**: Rig
- **æ¨¡å‹**: OpenAI GPT-4o-mini / text-embedding-3-small
- **PDF è§£æ**: pdf-extract

## å®‰è£…

\`\`\`bash
git clone https://github.com/yourusername/pdf-qa
cd pdf-qa
cargo build --release
\`\`\`

## ä½¿ç”¨

\`\`\`bash
export OPENAI_API_KEY="your-api-key"
./target/release/pdf-qa chat --file document.pdf
\`\`\`

## æ¼”ç¤º

[æ’å…¥ GIF æˆ–æˆªå›¾]

## æ¶æ„

\`\`\`
PDF â†’ è§£æ â†’ åˆ‡åˆ† â†’ Embedding â†’ å‘é‡ç´¢å¼•
                                    â†“
ç”¨æˆ·é—®é¢˜ â†’ Embedding â†’ ç›¸ä¼¼åº¦æœç´¢ â†’ æ£€ç´¢ç»“æœ
                                    â†“
                        LLM ç”Ÿæˆå›ç­” â† ä¸Šä¸‹æ–‡
\`\`\`

## License

MIT
```

**åˆ¶ä½œæ¼”ç¤ºï¼š**
- ä½¿ç”¨ `asciinema` å½•åˆ¶ç»ˆç«¯æ¼”ç¤º
- æˆ–ä½¿ç”¨ `terminalizer` ç”Ÿæˆ GIF

---

### Day 28: å‘å¸ƒ

**ä»»åŠ¡æ¸…å•ï¼š**

1. **GitHub ä»“åº“**
   - [ ] åˆ›å»ºä»“åº“
   - [ ] æ¨é€ä»£ç 
   - [ ] æ·»åŠ  .gitignore
   - [ ] æ·»åŠ  LICENSE

2. **å®Œå–„ README**
   - [ ] æ·»åŠ  badgesï¼ˆbuild statusã€licenseï¼‰
   - [ ] ç¡®ä¿å®‰è£…æ­¥éª¤å¯è¡Œ

3. **LinkedIn / åšå®¢**
   - [ ] å†™ä¸€ç¯‡é¡¹ç›®ä»‹ç»ï¼ˆå¯é€‰ï¼‰
   - [ ] åˆ†äº«åˆ°æŠ€æœ¯ç¤¾åŒº

---

## å­¦ä¹ èµ„æºæ±‡æ€»

### å®˜æ–¹æ–‡æ¡£
- Rust Book: https://doc.rust-lang.org/book/
- Async Book: https://rust-lang.github.io/async-book/
- Tokio Tutorial: https://tokio.rs/tokio/tutorial
- Rig Docs: https://docs.rs/rig-core/

### æ¨èé˜…è¯»
- Rust by Example: https://doc.rust-lang.org/rust-by-example/
- Zero to Production in Rust: https://www.zero2prod.com/

### ç¤¾åŒº
- Rust ä¸­æ–‡ç¤¾åŒº: https://rustcc.cn/
- Rust å®˜æ–¹ Discord
- r/rust on Reddit

---

## è¿›åº¦è¿½è¸ª

| å‘¨ | ä¸»é¢˜ | çŠ¶æ€ |
|----|------|------|
| 1 | å¼‚æ­¥ Rust | â¬œ æœªå¼€å§‹ |
| 2 | Rig åŸºç¡€ | â¬œ æœªå¼€å§‹ |
| 3 | é¡¹ç›®å¼€å‘ | â¬œ æœªå¼€å§‹ |
| 4 | å®Œå–„éƒ¨ç½² | â¬œ æœªå¼€å§‹ |

---

> ğŸ’¡ æç¤ºï¼šæ¯å¤©å­¦ä¹ åï¼Œåœ¨æ­¤æ–‡æ¡£ä¸­å‹¾é€‰å®Œæˆçš„ä»»åŠ¡ï¼Œä¾¿äºè¿½è¸ªè¿›åº¦ã€‚
